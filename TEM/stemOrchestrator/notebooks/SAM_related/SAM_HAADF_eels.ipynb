{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9dc7ff4",
   "metadata": {},
   "source": [
    "## Segment Anything Model (SAM) - EELS: live workflow\n",
    "- Acquire an image using HAADF detector\n",
    "- Feed HAADF image in SAM pipeline:\n",
    "        - get particles with segmented masks\n",
    "        - find center point of each particle\n",
    "- Acquire eels detector signals at center of each particle\n",
    "#### Contributor(s): Utkarsh Pratiush <utkarshp1161@gmail.com> - 2nd May 2025\n",
    "#### edited - \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38553b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stemOrchestrator.acquisition import TFacquisition, DMacquisition\n",
    "from stemOrchestrator.simulation import DMtwin\n",
    "from stemOrchestrator.process import HAADF_tiff_to_png, tiff_to_png\n",
    "from autoscript_tem_microscope_client import TemMicroscopeClient\n",
    "from stemOrchestrator.logging_config   import setup_logging\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "plot = plt\n",
    "from typing import Dict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00938db",
   "metadata": {},
   "outputs": [],
   "source": [
    "########SAM part ********************************************************************************************************\n",
    "\n",
    "from stemOrchestrator.MLlayer.MLlayerSAM import setup_device, download_sam_model, initialize_sam_model, preprocess_image, generate_and_save_masks, create_normalized_particle_positions, display_image_with_masks, display_image_with_labels, extract_mask_contours, generate_mask_colors, visualize_masks_with_boundaries, extract_particle_data, print_boundary_points_info, plot_centroids, sample_particle_positions, plot_sampled_positions, create_visualization_with_masks\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray \n",
    "from typing import List, Dict, Union\n",
    "\n",
    "\n",
    "def run_sam(image_data: np.ndarray, path_folder: str) -> Union[List, Dict]:\n",
    "    \"\"\"Main function to run SAM segmentation pipeline.\"\"\"\n",
    "    device = setup_device()\n",
    "    \n",
    "    model_type = \"vit_b\"  # Options: 'vit_b', 'vit_l', 'vit_h'\n",
    "    checkpoint_url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\"\n",
    "    checkpoint_path = \"sam_vit_b_01ec64.pth\"\n",
    "    download_sam_model(model_type, checkpoint_url, checkpoint_path)\n",
    "    sam, mask_generator = initialize_sam_model(model_type, checkpoint_path, device)\n",
    "    img_np = preprocess_image(image_data)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Generate and visualize masks\n",
    "    masks_path = f'{path_folder}/masks_Au_online.pkl'\n",
    "    masks = generate_and_save_masks(mask_generator, img_np, masks_path)\n",
    "    visual_image, centroids = create_visualization_with_masks(img_np, masks)\n",
    "    display_image_with_masks(visual_image, \"Image with Segmentation Masks\")\n",
    "    display_image_with_labels(visual_image, centroids, \"Image with Segmentation Masks and Labels\")\n",
    "    \n",
    "    mask_contours = extract_mask_contours(masks)\n",
    "    mask_colors = generate_mask_colors(len(masks))\n",
    "    boundaries_path = f\"{path_folder}/Segmentation Masks with Boundaries and Centroids.png\"\n",
    "    visualize_masks_with_boundaries(visual_image, centroids, mask_contours, mask_colors, boundaries_path)\n",
    "    particles = extract_particle_data(masks)\n",
    "    # Save particle data\n",
    "    with open(f'{path_folder}/particles.pkl', 'wb') as f:\n",
    "        pickle.dump(particles, f)\n",
    "    \n",
    "    print_boundary_points_info(particles)\n",
    "    centroids_array = np.array(centroids)\n",
    "    plot_centroids(centroids_array, img_np)\n",
    "    positions_sampled = sample_particle_positions(particles, img_np)\n",
    "    plot_sampled_positions(positions_sampled, img_np, len(centroids))\n",
    "    each_particle_position = create_normalized_particle_positions(particles, img_np.shape[:2])\n",
    "    with open(f'{path_folder}/sampled_boundary_pts_particles.pkl', 'wb') as f: # Save normalized particle positions\n",
    "        pickle.dump(each_particle_position, f)\n",
    "    \n",
    "    all_particle_keys = each_particle_position.keys()\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"Processing complete!\")\n",
    "    return all_particle_keys, each_particle_position\n",
    "\n",
    "##########****************************************************************************************************************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config :Dict) -> None:\n",
    "    ip = config[\"ip\"]\n",
    "    port = config[\"port\"]\n",
    "    haadf_exposure = config[\"haadf_exposure\"]\n",
    "    haadf_resolution = config[\"haadf_resolution\"]\n",
    "    out_path = config[\"out_path\"]\n",
    "    setup_logging(out_path=out_path)\n",
    "    \n",
    "\n",
    "    microscope_tf = TemMicroscopeClient()\n",
    "    microscope_tf.connect(ip, port = port)# 7521 on velox  computer\n",
    "    # microscope_dm = DMtwin()\n",
    "    # query state:\n",
    "\n",
    "    global tf_acquisition\n",
    "    tf_acquisition = TFacquisition(microscope=microscope_tf, offline=True)\n",
    "    # dm_acquisition = DMacquisition(microscope=microscope_dm, offline=True)\n",
    "    dm_acquisition  = DMtwin()\n",
    "\n",
    "\n",
    "\n",
    "    # Get haadf\n",
    "    haadf_np_array, haadf_tiff_name = tf_acquisition.acquire_haadf(exposure = haadf_exposure, resolution=haadf_resolution)\n",
    "\n",
    "    HAADF_tiff_to_png(haadf_tiff_name)\n",
    "    logging.info(\"END acquisition.\")\n",
    "    \n",
    "    all_particle_keys, each_particle_position = run_sam(haadf_np_array, out_path)\n",
    "    \n",
    "    \n",
    "\n",
    "    def acquire_and_plot_combined(image_data, particle_key, particle_dict, eels_exposure, eels_offset):\n",
    "        \"\"\"Acquire EDS spectrum, CETA image, and plot all three components in a single figure.\"\"\"\n",
    "        \n",
    "        \n",
    "        # lets do just eels at boundary points\n",
    "        print(f\"eels for particle{particle_key}\")\n",
    "        # Ensure the directory exists\n",
    "        directory = f'{out_path}/particle{particle_key}'\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        # Get EELS spectrum\n",
    "        tf_acquisition.unblank_beam()\n",
    "        # array_server.acquire_camera(exposure = eels_exposure)\n",
    "        dm_acquisition.acquire_camera(exposure = eels_exposure)\n",
    "        tf_acquisition.blank_beam() # blank the beam\n",
    "        # array_list, shape, dtype = array_server.get_eels()# 0.15 is the scaling factor, dipersion\n",
    "        array_list, shape, dtype  = dm_acquisition.get_eels()\n",
    "        spec_eels = np.array(array_list, dtype=dtype).reshape(shape)\n",
    "        # np.savez(\"data/eels_.npz\", spec = array)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Get the current beam position\n",
    "        position = tf_acquisition.query_paused_beam_positon()\n",
    "        x = position.x\n",
    "        y = position.y\n",
    "        formatted_position = f\"({x:.2g}, {y:.2g})\"\n",
    "\n",
    "        # Create a figure with three subplots\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "        # Plot the acquired image data\n",
    "        axs[0].imshow(image_data, cmap='gray')\n",
    "        axs[0].set_title('Acquired Image')\n",
    "        axs[0].set_axis_off()  # Hide axes for the image plot\n",
    "        axs[0].scatter(x * image_data.shape[0], y * image_data.shape[1], c='r', s=100, marker='x', label=f\"Position: {formatted_position}\")\n",
    "        \n",
    "        axs[1].plot(np.array(range(len(spec_eels))) - eels_offset, spec_eels)# -25 is the offset\n",
    "        axs[1].set_title('Acquired EELS Spectrum')\n",
    "        axs[1].set_xlabel(\"Energy loss (eV)\")\n",
    "        axs[1].set_ylabel('Intensity Counts')\n",
    "        \n",
    "        \n",
    "        # axs[3].legend()\n",
    "\n",
    "        # Adjust layout and display\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{out_path}/particle{particle_key}/haadf_eels_at_centroid of particle{particle_key}_{formatted_position}.png', dpi = 300)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        # save the ceta and spectrum data\n",
    "        # np.save(f'{path_folder}/ceta image at position {formatted_position}.npy', ceta_image_data)# ceta image save\n",
    "        # np.save(f'{path_folder}/EDX_spectrum at position {formatted_position}.npy', spec)# eds spectrum save\n",
    "        np.save(f'{out_path}/particle{particle_key}/eels at centroid of particle{particle_key}_{formatted_position}.npy', spec_eels)# eels spectrum save\n",
    "        # ceta_image.save(f'{path_folder}/ceta_raw_ at position {formatted_position}.tiff')\n",
    "\n",
    "\n",
    "        import threading\n",
    "        import time\n",
    "        def move_beam(tf_acquisition, boundary_pt_array, eels_exposure):\n",
    "            print(\"beam movement started\")\n",
    "            tf_acquisition.unblank_beam()\n",
    "\n",
    "            for pts in boundary_pt_array:\n",
    "                point = list(pts)\n",
    "                tf_acquisition.move_paused_beam(point[0], point[1])\n",
    "                position = tf_acquisition.query_paused_beam_positon()\n",
    "                x = position.x\n",
    "                y = position.y\n",
    "                formatted_position = f\"({x:.4g}, {y:.4g})\"\n",
    "                print(f\"Beam positioned at: {formatted_position}\")\n",
    "                time.sleep(eels_exposure/len(boundary_pt_array)*0.8)# eels exposure per point\n",
    "            print(\"Beam scanning complete.\")\n",
    "            tf_acquisition.blank_beam()\n",
    "\n",
    "        def acquire_eels_data(dm_acquisition, eels_exposure):\n",
    "            print(\"EELS acquisition started.\")\n",
    "            dm_acquisition.acquire_camera(exposure=eels_exposure)\n",
    "            print(\"EELS acquisition complete.\")\n",
    "\n",
    "        boundary_pt_array = particle_dict[particle_key][\"boundary_points\"]\n",
    "\n",
    "        beam_thread = threading.Thread(target=move_beam, args=(tf_acquisition, boundary_pt_array,  eels_exposure))\n",
    "        beam_thread.start()\n",
    "\n",
    "        # Run EELS acquisition in parallel\n",
    "        acquire_eels_data(dm_acquisition, eels_exposure)\n",
    "        tf_acquisition.blank_beam()\n",
    "        # Wait for beam movement to finish\n",
    "        beam_thread.join()### I think exposure should be high enough so all the points is covered\n",
    "\n",
    "        # Once both tasks are done, retrieve and save the EELS data\n",
    "        array_list, shape, dtype = dm_acquisition.get_eels()\n",
    "        spec_eels = np.array(array_list, dtype=dtype).reshape(shape)\n",
    "        \n",
    "        plt.close()\n",
    "        # Plot and save the single EELS spectrum\n",
    "        plt.plot(np.array(range(len(spec_eels))) - eels_offset, spec_eels)\n",
    "        plt.title('Acquired EELS Spectrum for All Boundary Points')\n",
    "        plt.xlabel(\"Energy loss (eV)\")\n",
    "        plt.ylabel('Intensity Counts')\n",
    "        plt.savefig(f\"{out_path}/particle{particle_key}/eels_acquisition_combined_boundary_particle{particle_key}.png\")\n",
    "        plt.close()\n",
    "        np.save(f'{out_path}/particle{particle_key}/eels_acquisition_combined_boundary_particle{particle_key}.npy', spec_eels)\n",
    "\n",
    "\n",
    "    def run_acquisition_for_particle(image_data, particle_key, particle_dict, eels_exposure, eels_offset):\n",
    "        \"\"\"Run the entire acquisition process for a given position.\"\"\"\n",
    "        position = list(particle_dict[particle_key][\"centroid\"])\n",
    "        tf_acquisition.move_paused_beam(position[0], position[1])\n",
    "\n",
    "        acquire_and_plot_combined(image_data, particle_key, particle_dict, eels_exposure, eels_offset)\n",
    "\n",
    "    spec_metadata_dict = {\"eels_exposure_sec\" : 0.05, \"eels_offset\": 0}\n",
    "\n",
    "    eels_exposure = spec_metadata_dict[\"eels_exposure_sec\"]\n",
    "    eels_offset = spec_metadata_dict[\"eels_offset\"]\n",
    "\n",
    "    file_path = f'{out_path}/spectrometer_metadata_dict.pkl'\n",
    "    # Save the dictionary to disk\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(spec_metadata_dict, file)\n",
    "    print(f\"spectrometer_metadata_dictsaved to {file_path}\")\n",
    "\n",
    "    for particle_key in all_particle_keys:\n",
    "        run_acquisition_for_particle(haadf_np_array,particle_key, each_particle_position, eels_exposure, eels_offset)# 25 seconds per reading: --> 1min 35 seconds for 4 points\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de33e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize to None\n",
    "ip = os.getenv(\"MICROSCOPE_IP\")\n",
    "port = os.getenv(\"MICROSCOPE_PORT\")\n",
    "uri_eels_ip = None\n",
    "uri_eels_port = None\n",
    "\n",
    "if not ip or not port:\n",
    "    secret_path = Path(\"../../config_secret.json\")\n",
    "    if secret_path.exists():\n",
    "        with open(secret_path, \"r\") as f:\n",
    "            secret = json.load(f)\n",
    "            ip = ip or secret.get(\"ip_TF_sim\")\n",
    "            port = port or secret.get(\"port_TF_sim\")\n",
    "            uri_eels_ip = uri_eels_ip or secret.get(\"uri_eels_ip\")\n",
    "            uri_eels_port = uri_eels_port or secret.get(\"uri_eels_port\")\n",
    "\n",
    "if not ip:\n",
    "    ip = input(\"Enter microscope IP: \")\n",
    "if not port:\n",
    "    port = input(\"Enter microscope Port: \")\n",
    "\n",
    "try:\n",
    "    port = int(port)\n",
    "except ValueError:\n",
    "    raise ValueError(\"Port must be an integer\")\n",
    "\n",
    "config = {\n",
    "    \"ip\": ip,\n",
    "    \"port\": port,\n",
    "    \"uri_eels_ip\": uri_eels_ip,\n",
    "    \"uri_eels_port\": uri_eels_port,\n",
    "    \"haadf_exposure\": 40e-8,  # microseconds per pixel\n",
    "    \"haadf_resolution\": 512,  # square\n",
    "    \"out_path\": \".\"\n",
    "}\n",
    "\n",
    "main(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e301ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb74130b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmclient_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
