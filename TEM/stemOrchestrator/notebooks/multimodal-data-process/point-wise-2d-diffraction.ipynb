{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b22e939",
   "metadata": {},
   "source": [
    "## HAADF and Diffraction only\n",
    "- Haadf\n",
    "- sample 20 locations - get diffraction\n",
    "- pca plots of eels on the haadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a5ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stemOrchestrator.logging_config import setup_logging\n",
    "\n",
    "data_folder = \".\"\n",
    "out_path = data_folder\n",
    "setup_logging(out_path=out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stemOrchestrator.acquisition import TFacquisition, DMacquisition\n",
    "from stemOrchestrator.simulation import DMtwin\n",
    "from stemOrchestrator.process import HAADF_tiff_to_png, tiff_to_png\n",
    "from autoscript_tem_microscope_client import TemMicroscopeClient\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import Pyro5.api\n",
    "\n",
    "plot = plt\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae5463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "ip = os.getenv(\"MICROSCOPE_IP\")\n",
    "port = os.getenv(\"MICROSCOPE_PORT\")\n",
    "\n",
    "if not ip or not port:\n",
    "    secret_path = Path(\"../../config_secret.json\")\n",
    "    if secret_path.exists():\n",
    "        with open(secret_path, \"r\") as f:\n",
    "            secret = json.load(f)\n",
    "            ip = ip or secret.get(\"ip_TF\")\n",
    "            port = port or secret.get(\"port_TF\")\n",
    "\n",
    "\n",
    "if ip is None:\n",
    "    print(\"please check path of yaml file containing ip and port info\")\n",
    "\n",
    "else:\n",
    "    print(\"your yaml file with ip and port loaded fine\")\n",
    "config = {\n",
    "    \"ip\": ip,\n",
    "    \"port\": port,\n",
    "    \"haadf_exposure\": 40e-8,  # micro-seconds per pixel\n",
    "    \"haadf_resolution\": 512,  # square\n",
    "    \"out_path\": \".\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = config[\"ip\"]\n",
    "port = config[\"port\"]\n",
    "haadf_exposure = config[\"haadf_exposure\"]\n",
    "out_path = config[\"out_path\"]\n",
    "haadf_resolution = config[\"haadf_resolution\"]\n",
    "\n",
    "\n",
    "microscope = TemMicroscopeClient()\n",
    "microscope.connect(ip, port=port)  # 7521 on velox  computer\n",
    "# microscope.connect( port = port)# 7521 on velox  computer\n",
    "\n",
    "# query state:\n",
    "\n",
    "tf_acquisition = TFacquisition(microscope=microscope, offline=False)\n",
    "uri = \"PYRO:array.server@10.46.217.242:9094\"\n",
    "\n",
    "\n",
    "# put beam shift to 0,0\n",
    "# tf_acquisition.move_beam_shift_positon([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get haadf from mic\n",
    "\n",
    "# Get haadf\n",
    "haadf_np_array, haadf_tiff_name = tf_acquisition.acquire_haadf(\n",
    "    exposure=haadf_exposure, resolution=haadf_resolution\n",
    ")\n",
    "\n",
    "HAADF_tiff_to_png(haadf_tiff_name)\n",
    "haadf = haadf_np_array\n",
    "\n",
    "W, H = haadf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf50cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best haadf after normalization\n",
    "haadf_normalized = haadf\n",
    "\n",
    "plt.imshow(haadf_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a1e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds positions to sample from\n",
    "import numpy as np\n",
    "N = 20\n",
    "rng = np.random.default_rng(42)\n",
    "xs = rng.integers(0, W, size=N)\n",
    "ys = rng.integers(0, H, size=N)\n",
    "pixel_pos = np.stack([xs, ys], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1403e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot position sampled\n",
    "plt.imshow(haadf_normalized)\n",
    "plt.scatter(xs, ys, s=50, c=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d0b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get edx at those positon and stack them\n",
    "ceta_exposure = 0.1  # seconds\n",
    "ceta_resolution = 1024\n",
    "all_arrays = []  # 1. Create an empty list before the loop\n",
    "for point in pixel_pos:\n",
    "    # convert to fractional coordinates\n",
    "    x_pos = point[0] / W\n",
    "    y_pos = point[1] / H\n",
    "\n",
    "    # position beam\n",
    "    tf_acquisition.move_paused_beam(x_pos, y_pos)\n",
    "\n",
    "    # Acquire the EDS spectrum\n",
    "    microscope.optics.blanker.unblank()\n",
    "    ceta_cp_array, ceta_tiff_name = tf_acquisition.acquire_ceta_or_flucam(\n",
    "        exposure=ceta_exposure, resolution=ceta_resolution, camera=\"ceta\"\n",
    "    )    \n",
    "    microscope.optics.blanker.blank()\n",
    "    \n",
    "    # clip the bright spots\n",
    "    shifted_data = ceta_cp_array\n",
    "    p99 = np.percentile(shifted_data.ravel(), 99)\n",
    "    clipped_data = np.clip(shifted_data, 0, p99)\n",
    "    clipped_data -= clipped_data.min()\n",
    "    clipped_data /= clipped_data.max()\n",
    "    norm_data = clipped_data\n",
    "    # power law 2nd time through\n",
    "    gamma = 1\n",
    "    norm_data = norm_data**gamma\n",
    "    edge_crop = 256\n",
    "    norm_data = norm_data[edge_crop:-edge_crop, edge_crop:-edge_crop]\n",
    "    \n",
    "    plt.imshow(norm_data)\n",
    "    plt.show()\n",
    "\n",
    "    #######----> need to create energy axis but lets do later\n",
    "\n",
    "    # stack the arrays\n",
    "    all_arrays.append(norm_data)  # 2. Add the new array to the list\n",
    "\n",
    "spectra = np.stack(all_arrays, axis=0)\n",
    "print(spectra.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f0fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize spectra of shape (20, 512, 512)\n",
    "mins = spectra.min(axis=(1, 2), keepdims=True)\n",
    "ptps = np.ptp(spectra, axis=(1, 2), keepdims=True)\n",
    "ptps = np.where(ptps == 0, 1.0, ptps)\n",
    "spectra_norm = (spectra - mins) / ptps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# reshape to (20, 512*512)\n",
    "spectra_flat = spectra_norm.reshape(spectra_norm.shape[0], -1)\n",
    "\n",
    "k = 3\n",
    "pca = PCA(n_components=k, random_state=42)\n",
    "scores = pca.fit_transform(spectra_flat)  # shape (20, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74294b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imshow the pc1 values on the haadf\n",
    "# -----------------------------\n",
    "# 5) Plots\n",
    "# -----------------------------\n",
    "\n",
    "# a) HAADF overlay with PC1 color\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(haadf_normalized, cmap=\"gray\")\n",
    "plt.scatter(xs, ys, c=scores[:, 0], s=50)\n",
    "plt.title(\"HAADF + Diffraction PCA Overlay (PC1 color)\")\n",
    "plt.colorbar(label=\"PC1 score\", cmap=\"magma\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"/mnt/data/overlay_plot.png\", dpi=160)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22b9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans on PCA scores\n",
    "km = KMeans(n_clusters=3, n_init=10, random_state=42)\n",
    "cluster_labels = km.fit_predict(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) PCA scatter with clusters\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(scores[:, 0], scores[:, 1], s=8, alpha=0.8, c=cluster_labels)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA Scatter of Diffraction with KMeans Clusters\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"/mnt/data/pca_scatter.png\", dpi=160)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9248714f",
   "metadata": {},
   "source": [
    "## SAM + Diffraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ce352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stemOrchestrator.logging_config import setup_logging\n",
    "import os\n",
    "\n",
    "data_folder = \"out-diffraction/\"\n",
    "\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "out_path = data_folder\n",
    "setup_logging(out_path=out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02054bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stemOrchestrator.acquisition import TFacquisition, DMacquisition\n",
    "from stemOrchestrator.simulation import DMtwin\n",
    "from stemOrchestrator.process import HAADF_tiff_to_png, tiff_to_png\n",
    "from autoscript_tem_microscope_client import TemMicroscopeClient\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "plot = plt\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89614a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "ip = os.getenv(\"MICROSCOPE_IP\")\n",
    "port = os.getenv(\"MICROSCOPE_PORT\")\n",
    "\n",
    "if not ip or not port:\n",
    "    secret_path = Path(\"../../config_secret.json\")\n",
    "    if secret_path.exists():\n",
    "        with open(secret_path, \"r\") as f:\n",
    "            secret = json.load(f)\n",
    "            ip = ip or secret.get(\"ip_TF\")\n",
    "            port = port or secret.get(\"port_TF\")\n",
    "\n",
    "\n",
    "if ip is None:\n",
    "    print(\"please check path of yaml file containing ip and port info\")\n",
    "\n",
    "else:\n",
    "    print(\"your yaml file with ip and port loaded fine\")\n",
    "config = {\n",
    "    \"ip\": ip,\n",
    "    \"port\": port,\n",
    "    \"haadf_exposure\": 40e-8,  # micro-seconds per pixel\n",
    "    \"haadf_resolution\": 512,  # square\n",
    "    \"out_path\": f\"{data_folder}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = config[\"ip\"]\n",
    "port = config[\"port\"]\n",
    "haadf_exposure = config[\"haadf_exposure\"]\n",
    "out_path = config[\"out_path\"]\n",
    "haadf_resolution = config[\"haadf_resolution\"]\n",
    "\n",
    "\n",
    "microscope = TemMicroscopeClient()\n",
    "microscope.connect(ip, port=port)  # 7521 on velox  computer\n",
    "# microscope.connect( port = port)# 7521 on velox  computer\n",
    "\n",
    "# query state:\n",
    "\n",
    "tf_acquisition = TFacquisition(microscope=microscope)\n",
    "\n",
    "# put beam shift to 0,0\n",
    "# tf_acquisition.move_beam_shift_positon([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303b7fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get haadf from mic\n",
    "\n",
    "# Get haadf\n",
    "haadf_np_array, haadf_tiff_name = tf_acquisition.acquire_haadf(\n",
    "    exposure=haadf_exposure, resolution=haadf_resolution, folder_path=out_path\n",
    ")\n",
    "\n",
    "HAADF_tiff_to_png(out_path + haadf_tiff_name)\n",
    "haadf = haadf_np_array\n",
    "\n",
    "W, H = haadf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best haadf after normalization\n",
    "haadf_normalized = haadf_np_array\n",
    "\n",
    "plt.imshow(haadf_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f459eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get positons from sam\n",
    "\n",
    "########SAM part ********************************************************************************************************\n",
    "# -----> takes quite some time- 3 minutes-- to load --\n",
    "from stemOrchestrator.MLlayer.MLlayerSAM import (\n",
    "    setup_device,\n",
    "    download_sam_model,\n",
    "    initialize_sam_model,\n",
    "    preprocess_image,\n",
    "    generate_and_save_masks,\n",
    "    create_normalized_particle_positions,\n",
    "    display_image_with_masks,\n",
    "    display_image_with_labels,\n",
    "    extract_mask_contours,\n",
    "    generate_mask_colors,\n",
    "    visualize_masks_with_boundaries,\n",
    "    extract_particle_data,\n",
    "    print_boundary_points_info,\n",
    "    plot_centroids,\n",
    "    sample_particle_positions,\n",
    "    plot_sampled_positions,\n",
    "    create_visualization_with_masks,\n",
    ")\n",
    "import pickle\n",
    "import numpy as np\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "\n",
    "def run_sam(image_data: np.ndarray, path_folder: str) -> Union[List, Dict]:\n",
    "    \"\"\"Main function to run SAM segmentation pipeline.\"\"\"\n",
    "    device = setup_device()\n",
    "\n",
    "    model_type = \"vit_b\"  # Options: 'vit_b', 'vit_l', 'vit_h'\n",
    "    checkpoint_url = (\n",
    "        \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\"\n",
    "    )\n",
    "    checkpoint_path = \"sam_vit_b_01ec64.pth\"\n",
    "    download_sam_model(model_type, checkpoint_url, checkpoint_path)\n",
    "    sam, mask_generator = initialize_sam_model(model_type, checkpoint_path, device)\n",
    "    img_np = preprocess_image(image_data)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # Generate and visualize masks\n",
    "    masks_path = f\"{path_folder}/masks_Au_online.pkl\"\n",
    "    masks = generate_and_save_masks(mask_generator, img_np, masks_path)\n",
    "    visual_image, centroids = create_visualization_with_masks(img_np, masks)\n",
    "    display_image_with_masks(visual_image, \"Image with Segmentation Masks\")\n",
    "    display_image_with_labels(\n",
    "        visual_image, centroids, \"Image with Segmentation Masks and Labels\"\n",
    "    )\n",
    "\n",
    "    mask_contours = extract_mask_contours(masks)\n",
    "    mask_colors = generate_mask_colors(len(masks))\n",
    "    boundaries_path = (\n",
    "        f\"{path_folder}/Segmentation Masks with Boundaries and Centroids.png\"\n",
    "    )\n",
    "    visualize_masks_with_boundaries(\n",
    "        visual_image, centroids, mask_contours, mask_colors, boundaries_path\n",
    "    )\n",
    "    particles = extract_particle_data(masks)\n",
    "    # Save particle data\n",
    "    # with open(f'{path_folder}/particles.pkl', 'wb') as f:\n",
    "    #     pickle.dump(particles, f)\n",
    "\n",
    "    print_boundary_points_info(particles)\n",
    "    centroids_array = np.array(centroids)\n",
    "    plot_centroids(centroids_array, img_np)\n",
    "    positions_sampled = sample_particle_positions(particles, img_np)\n",
    "    plot_sampled_positions(positions_sampled, img_np, len(centroids))\n",
    "    each_particle_position = create_normalized_particle_positions(\n",
    "        particles, img_np.shape[:2]\n",
    "    )\n",
    "    # with open(f'{path_folder}/sampled_boundary_pts_particles.pkl', 'wb') as f: # Save normalized particle positions\n",
    "    #     pickle.dump(each_particle_position, f)\n",
    "\n",
    "    all_particle_keys = each_particle_position.keys()\n",
    "\n",
    "    print(\"Processing complete!\")\n",
    "    return all_particle_keys, each_particle_position\n",
    "\n",
    "\n",
    "##########****************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run the segmentaiotn on haadf to get particles\n",
    "from datetime import datetime\n",
    "\n",
    "print(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "all_particle_keys, each_particle_position = run_sam(\n",
    "    haadf_np_array, out_path\n",
    ")  ############ haadf normalized doesnt work here --- weird\n",
    "print(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af1fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds positions to sample from\n",
    "# N = 20\n",
    "rng = np.random.default_rng(42)\n",
    "# xs = rng.integers(0, W, size=N)\n",
    "# ys = rng.integers(0, H, size=N)\n",
    "# pixel_pos = np.stack([xs, ys], axis=1)\n",
    "\n",
    "centroids = np.array([v[\"centroid\"] for v in each_particle_position.values()])\n",
    "\n",
    "# Sample N random centroids (without replacement if fewer than N)\n",
    "N = len(centroids)\n",
    "rng = np.random.default_rng(42)\n",
    "idx = rng.choice(len(centroids), size=min(N, len(centroids)), replace=False)\n",
    "sampled = centroids[idx]\n",
    "\n",
    "# Separate xs and ys (keeping same data types as your original code)\n",
    "xs = sampled[:, 0] * W\n",
    "ys = sampled[:, 1] * H\n",
    "pixel_pos = np.stack([xs, ys], axis=1)\n",
    "\n",
    "print(\"xs:\", xs)\n",
    "print(\"ys:\", ys)\n",
    "print(\"pixel_pos:\\n\", pixel_pos)\n",
    "\n",
    "np.save(f\"{out_path}pixel_pos.npy\", pixel_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa675fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot position sampled\n",
    "plt.imshow(haadf_normalized)\n",
    "plt.scatter(xs, ys, s=50, c=\"r\")\n",
    "# want to save this? - nope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e68f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get edx at those positon and stack them\n",
    "ceta_exposure = 0.1  # seconds\n",
    "ceta_resolution = 1024\n",
    "all_arrays = []  # 1. Create an empty list before the loop\n",
    "for point in pixel_pos:\n",
    "    # convert to fractional coordinates\n",
    "    x_pos = point[0] / W\n",
    "    y_pos = point[1] / H\n",
    "\n",
    "    # position beam\n",
    "    tf_acquisition.move_paused_beam(x_pos, y_pos)\n",
    "\n",
    "    # Acquire the EDS spectrum\n",
    "    microscope.optics.blanker.unblank()\n",
    "    ceta_cp_array, ceta_tiff_name = tf_acquisition.acquire_ceta_or_flucam(\n",
    "        exposure=ceta_exposure, resolution=ceta_resolution, camera=\"ceta\", folder_path=out_path\n",
    "    )    \n",
    "    microscope.optics.blanker.blank()\n",
    "    \n",
    "    # clip the bright spots\n",
    "    shifted_data = ceta_cp_array\n",
    "    p99 = np.percentile(shifted_data.ravel(), 99)\n",
    "    clipped_data = np.clip(shifted_data, 0, p99)\n",
    "    clipped_data -= clipped_data.min()\n",
    "    clipped_data /= clipped_data.max()\n",
    "    norm_data = clipped_data\n",
    "    # power law 2nd time through\n",
    "    gamma = 1\n",
    "    norm_data = norm_data**gamma\n",
    "    edge_crop = 256\n",
    "    norm_data = norm_data[edge_crop:-edge_crop, edge_crop:-edge_crop]\n",
    "    \n",
    "    plt.imshow(norm_data)\n",
    "    plt.show()\n",
    "\n",
    "    #######----> need to create energy axis but lets do later\n",
    "\n",
    "    # stack the arrays\n",
    "    all_arrays.append(norm_data)  # 2. Add the new array to the list\n",
    "\n",
    "spectra = np.stack(all_arrays, axis=0)\n",
    "print(spectra.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize spectra of shape (20, 512, 512)\n",
    "mins = spectra.min(axis=(1, 2), keepdims=True)\n",
    "ptps = np.ptp(spectra, axis=(1, 2), keepdims=True)\n",
    "ptps = np.where(ptps == 0, 1.0, ptps)\n",
    "spectra_norm = (spectra - mins) / ptps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86cd53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raw spectra\n",
    "np.save(f\"{out_path}raw_spectra.npy\", spectra)\n",
    "np.save(f\"{out_path}normalized_spectra.npy\",spectra_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a52e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# reshape to (20, 512*512)\n",
    "spectra_flat = spectra_norm.reshape(spectra_norm.shape[0], -1)\n",
    "\n",
    "k = 3\n",
    "pca = PCA(n_components=k, random_state=42)\n",
    "scores = pca.fit_transform(spectra_flat)  # shape (20, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ca7598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imshow the pc1 values on the haadf\n",
    "# -----------------------------\n",
    "# 5) Plots\n",
    "# -----------------------------\n",
    "\n",
    "# a) HAADF overlay with PC1 color\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(haadf_normalized, cmap=\"gray\")\n",
    "plt.scatter(xs, ys, c=scores[:, 0], s=50)\n",
    "plt.title(\"HAADF + Diffraction PCA Overlay (PC1 color)\")\n",
    "plt.colorbar(label=\"PC1 score\", cmap=\"magma\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"/mnt/data/overlay_plot.png\", dpi=160)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d391db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans on PCA scores\n",
    "km = KMeans(n_clusters=3, n_init=10, random_state=42)\n",
    "cluster_labels = km.fit_predict(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) PCA scatter with clusters\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(scores[:, 0], scores[:, 1], s=8, alpha=0.8, c=cluster_labels)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA Scatter of Diffraction with KMeans Clusters\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"/mnt/data/pca_scatter.png\", dpi=160)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b595c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stemorchestrator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
